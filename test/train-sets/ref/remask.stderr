Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.317229   0.317229            3         3.0   0.0000   0.5262       57
0.270263   0.223297            6         6.0   1.0000   0.2209       31
0.217912   0.155090           11        11.0   0.0000   0.2572       38
0.242425   0.266938           22        22.0   1.0000   0.7009       88
0.218850   0.195276           44        44.0   0.0000   0.3510       66
0.214091   0.209220           87        87.0   1.0000   0.4271       61
0.194782   0.175474          174       174.0   1.0000   0.0736       26

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200
weighted label sum = 91
average loss = 0.189489
best constant = 0.455
best constant's loss = 0.247975
total feature number = 15482
